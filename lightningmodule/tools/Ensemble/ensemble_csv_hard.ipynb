{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 설정\n",
    "- input_dir: CSV 파일이 저장된 디렉토리 경로\n",
    "- output_csv: 앙상블 결과를 저장할 파일 경로\n",
    "- iou_threshold: IOU 기준값(박스/마스크 병합 기준)\n",
    "- vote_threshold: 특정 예측을 유지하기 위한 최소 모델 투표 수\n",
    "\n",
    "RLE 처리 함수\n",
    "- decode_rle: RLE 데이터를 binary mask로 변환\n",
    "- encode_rle: binary mask를 RLE 데이터로 변환\n",
    "\n",
    "앙상블 수행\n",
    "- 동일한 image_name과 class에 대한 RLE를 IOU와 다수결 기준으로 병합\n",
    "- IOU가 기준치를 넘는 마스크만 병합\n",
    "- 다수결 기준(vote_threshold)을 만족하는 마스크만 최종 결과에 포함\n",
    "\n",
    "결과 저장\n",
    "- 결과를 output_csv로 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 설정\n",
    "\n",
    "# CSV 파일이 위치한 디렉토리 경로\n",
    "input_dir = \"/data/ephemeral/home/kjh2/level2-cv-semanticsegmentation-cv-13-lv3/inference/\"\n",
    "\n",
    "# 결과를 저장할 파일명\n",
    "output_csv = \"csv_ensemble_hard_1.csv\"  \n",
    "\n",
    "# 병합할 RLE 간 IOU 임계값\n",
    "iou_threshold = 0.5  \n",
    "\n",
    "# 최소 투표 수\n",
    "vote_threshold = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# GPU/CPU 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_rle(rle, shape):\n",
    "    #RLE 데이터를 디코딩해 binary mask를 생성    \n",
    "    if not rle or rle == '' or pd.isna(rle):  # NaN 값 처리\n",
    "        return torch.zeros(shape, dtype=torch.uint8, device=device)\n",
    "    \n",
    "    # 문자열로 변환 후 처리\n",
    "    s = list(map(int, str(rle).split()))\n",
    "    starts, lengths = s[0::2], s[1::2]\n",
    "    starts = torch.tensor(starts, device=device) - 1\n",
    "    ends = starts + torch.tensor(lengths, device=device)\n",
    "\n",
    "    mask = torch.zeros(shape[0] * shape[1], dtype=torch.uint8, device=device)\n",
    "    for start, end in zip(starts, ends):\n",
    "        mask[start:end] = 1\n",
    "    return mask.view(shape)\n",
    "\n",
    "def encode_rle(mask):\n",
    "    #binary mask를 RLE 형식으로 변환 (벡터화 버전)\n",
    "    mask = mask.flatten().cpu().numpy()  # 1D 배열로 변환\n",
    "    pixels = np.concatenate([[0], mask, [0]])  # 경계처리를 위해 앞뒤에 0 추가\n",
    "    diffs = np.where(pixels[1:] != pixels[:-1])[0]  # 값이 바뀌는 위치 찾기\n",
    "    starts = diffs[::2] + 1  # 1의 시작 위치 (1-based 인덱스)\n",
    "    lengths = diffs[1::2] - diffs[::2]  # 1의 길이\n",
    "    rle = \" \".join(f\"{start} {length}\" for start, length in zip(starts, lengths))\n",
    "    return rle\n",
    "\n",
    "def calculate_iou(mask1, mask2):\n",
    "    #두 binary mask 간의 IOU를 계산\n",
    "    intersection = (mask1 & mask2).sum().float()\n",
    "    union = (mask1 | mask2).sum().float()\n",
    "    if union == 0:\n",
    "        return torch.tensor(0.0, device=device)\n",
    "    return intersection / union\n",
    "\n",
    "def ensemble_csvs(csv_files, iou_threshold=0.5, vote_threshold=2):\n",
    "    #CSV 파일들을 앙상블하여 최종 결과 생성\n",
    "    all_predictions = defaultdict(list)\n",
    "\n",
    "    # 모든 CSV 파일 로드\n",
    "    for csv_file in tqdm(csv_files, desc=\"CSV 파일 로딩 중\"):\n",
    "        df = pd.read_csv(csv_file)\n",
    "        for _, row in df.iterrows():\n",
    "            image_name = row['image_name']\n",
    "            class_name = row['class']\n",
    "            rle = row['rle']\n",
    "            all_predictions[(image_name, class_name)].append(rle)\n",
    "    \n",
    "    # 앙상블 결과 저장\n",
    "    ensemble_results = []\n",
    "    for (image_name, class_name), rles in tqdm(all_predictions.items(), desc=\"앙상블 처리 중\"):\n",
    "        masks = [decode_rle(rle, shape=(2048, 2048)) for rle in rles]  # 모든 RLE를 binary mask로 변환\n",
    "        \n",
    "        final_mask = torch.zeros_like(masks[0], dtype=torch.uint8)\n",
    "        for i in range(len(masks)):\n",
    "            vote_count = 0\n",
    "            temp_mask = torch.zeros_like(masks[0], dtype=torch.uint8)\n",
    "            for j in range(len(masks)):\n",
    "                iou = calculate_iou(masks[i], masks[j])\n",
    "                if iou >= iou_threshold:\n",
    "                    vote_count += 1\n",
    "                    temp_mask |= masks[j]  # 겹치는 영역을 병합\n",
    "            if vote_count >= vote_threshold:\n",
    "                final_mask |= temp_mask  # 최종 마스크에 반영\n",
    "        \n",
    "        if final_mask.sum() > 0:\n",
    "            ensemble_rle = encode_rle(final_mask)\n",
    "            ensemble_results.append({\n",
    "                'image_name': image_name,\n",
    "                'class': class_name,\n",
    "                'rle': ensemble_rle\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(ensemble_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "발견된 CSV 파일 수: 4\n",
      "- /data/ephemeral/home/kjh2/level2-cv-semanticsegmentation-cv-13-lv3/inference/UPerNet_efficientnet-b7_2048_epoch100.csv\n",
      "- /data/ephemeral/home/kjh2/level2-cv-semanticsegmentation-cv-13-lv3/inference/segformer_from_mmseg.csv\n",
      "- /data/ephemeral/home/kjh2/level2-cv-semanticsegmentation-cv-13-lv3/inference/UPerNet mit_b5 1024.csv\n",
      "- /data/ephemeral/home/kjh2/level2-cv-semanticsegmentation-cv-13-lv3/inference/SAM2UNet_1024p_1e-4_amp_best.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CSV 파일 로딩 중: 100%|██████████| 4/4 [00:02<00:00,  1.60it/s]\n",
      "앙상블 처리 중: 100%|██████████| 8352/8352 [08:47<00:00, 15.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "앙상블 결과가 저장되었습니다: csv_ensemble_hard_1.csv\n"
     ]
    }
   ],
   "source": [
    "# 실행 부분\n",
    "if __name__ == \"__main__\":\n",
    "    # 입력 디렉토리 내의 모든 CSV 파일 경로를 가져옴\n",
    "    csv_files = glob(os.path.join(input_dir, '*.csv'))\n",
    "    if not csv_files:\n",
    "        raise ValueError(f\"입력 디렉토리에서 CSV 파일을 찾을 수 없음: {input_dir}\")\n",
    "    \n",
    "    print(f\"CSV 파일 수: {len(csv_files)}\")\n",
    "    for csv_file in csv_files:\n",
    "        print(f\"- {csv_file}\")\n",
    "    \n",
    "    # 앙상블 수행\n",
    "    ensemble_result_df = ensemble_csvs(\n",
    "        csv_files=csv_files,\n",
    "        iou_threshold=iou_threshold,\n",
    "        vote_threshold=vote_threshold\n",
    "    )\n",
    "\n",
    "    # 결과 저장\n",
    "    ensemble_result_df.to_csv(output_csv, index=False)\n",
    "    print(f\"앙상블 끝!!!!!!: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
